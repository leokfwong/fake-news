{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch News Quotes and Labels\n",
    "The function below scans the Politfact webpage and extracts different information related to political quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchNews(label, page_start, page_end, df=None):\n",
    "    \"\"\"Function used to scrape the news articles page by page\n",
    "    \n",
    "    Args:\n",
    "        label (str): 'true', 'mostly-true', 'half-true', 'barely-true', 'false', 'pants-fire'\n",
    "        page_start (int): Number of first page\n",
    "        page_end (int): Number of last page\n",
    "        \n",
    "    Returns:\n",
    "        df_raw (DataFrame): dataframe containing the news quotes\n",
    "    \n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        existing_quotes = []\n",
    "    else:\n",
    "        existing_quotes = list(df['quote'])\n",
    "    \n",
    "    # Initialize empty dataframe\n",
    "    df_raw = pd.DataFrame()\n",
    "\n",
    "    # Iterate through range of pages (or until last available)\n",
    "    for page_num in range(page_start, page_end):\n",
    "        \n",
    "        # Fetch page = page_num, fetch all news articles\n",
    "        html = requests.get(f'https://www.politifact.com/factchecks/list/?page={page_num}&ruling={label}')\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        articles = soup.findAll('div', {'class': 'm-statement__quote'})\n",
    "\n",
    "        # If 'pfhead' class is found, it means the page couldn't be found; otherwise returns None\n",
    "        error = soup.find('div', {'class': 'pfhead'})\n",
    "\n",
    "        if error == None:\n",
    "            \n",
    "            print(f'Fetching {label} news page {page_num}...')\n",
    "\n",
    "            # Iterate through articles\n",
    "            for article in articles:\n",
    "                \n",
    "                # Fetch artcile page\n",
    "                url = re.search(r'<a href=\"(.*)\">', str(article)).group(1)\n",
    "                html = requests.get(f'https://www.politifact.com{url}')\n",
    "                soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "                # Fetch raw content from divs\n",
    "                quote_raw = soup.find('div', {'class': 'm-statement__quote'}).text\n",
    "                author_raw = soup.find('a', {'class': 'm-statement__name'}).text\n",
    "                context_raw = str(soup.find('div', {'class': 'm-statement__desc'}))\n",
    "                categories_raw = soup.findAll('li', {'class': 'm-list__item'})\n",
    "                staff_raw = str(soup.findAll('div', {'class': 'm-author__content'}))\n",
    "\n",
    "                # Clean up data a little\n",
    "                quote = quote_raw.strip()\n",
    "                author = author_raw.strip()\n",
    "                date_regex = re.search(r'on ([A-Za-z]+ \\d{1,2}, \\d{4}) in', context_raw)\n",
    "                date = date_regex.group(1) if date_regex is not None else 'unspecified'\n",
    "                context_regex = re.search(r'\\d{4} in?(.*)', context_raw)\n",
    "                context = context_regex.group(1).strip().strip(':') if context_regex is not None else 'unspecified'\n",
    "                categories = ', '.join(re.findall(r'title=\\\"(.*)\\\">', str(categories_raw[:-1])))\n",
    "                staff = ', '.join(re.findall(r'>(.*)</a>', staff_raw))\n",
    "                \n",
    "                if quote not in existing_quotes:\n",
    "    \n",
    "                    # Create row\n",
    "                    row = pd.DataFrame({\n",
    "                        'label': [label], \n",
    "                        'quote': [quote], \n",
    "                        'context': [context], \n",
    "                        'author': [author], \n",
    "                        'date': [date], \n",
    "                        'categories': [categories],\n",
    "                        'staff': [staff]\n",
    "                    })\n",
    "\n",
    "                    # Append row to dataframe\n",
    "                    df_raw = df_raw.append(row, ignore_index=True)\n",
    "\n",
    "                    # Sleep for a few seconds, be nice to web servers :)\n",
    "                    pause = random.randint(3, 5)\n",
    "                    #print(f'Fetched news from page {page_num}, sleeping for {pause} seconds.')\n",
    "                    time.sleep(pause)\n",
    "                else:\n",
    "                    print(f'Entry already exists! Stopping execution...')\n",
    "                    print(f'Done! Updated dataset with {label} news from pages {page_start} to {page_num}.')\n",
    "                    return(df_raw.append(df, ignore_index=True).reset_index())\n",
    "\n",
    "        else:\n",
    "            page_end = page_num\n",
    "            break\n",
    "    \n",
    "    \n",
    "    print(f'Done! Fetched all {label} news from pages {page_start} to {page_end}.')\n",
    "    return(df_raw.reset_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it takes some time to retrieve the data, it's best to separate by label and do the extraction in segments. The `page_start` and `page_end` parameters allow us to set the range of pages to collect. Since the maximum number of pages changes as more news items are added with time, simply set `page_end` to a high value (ie. `1000`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching true news page 1...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with true news from pages 1 to 1.\n"
     ]
    }
   ],
   "source": [
    "# true_df = FetchNews('true', 1, 3)\n",
    "true_df = FetchNews('true', 1, 3, pd.read_csv('datasets/true.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostly True News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching mostly-true news page 1...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with mostly-true news from pages 1 to 1.\n"
     ]
    }
   ],
   "source": [
    "#mostly_true_df = FetchNews('mostly-true', 1, 3)\n",
    "mostly_true_df = FetchNews('mostly-true', 1, 1000, pd.read_csv('datasets/mostly-true.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half True News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching half-true news page 1...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with half-true news from pages 1 to 1.\n"
     ]
    }
   ],
   "source": [
    "#half_true_df = FetchNews('half-true', 1, 3)\n",
    "half_true_df = FetchNews('half-true', 1, 1000, pd.read_csv('datasets/half-true.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barely True News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching barely-true news page 1...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with barely-true news from pages 1 to 1.\n"
     ]
    }
   ],
   "source": [
    "#barely_true_df = FetchNews('barely-true', 1, 3)\n",
    "barely_true_df = FetchNews('barely-true', 1, 1000, pd.read_csv('datasets/barely-true.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching false news page 1...\n",
      "Fetching false news page 2...\n",
      "Fetching false news page 3...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with false news from pages 1 to 3.\n"
     ]
    }
   ],
   "source": [
    "#false_df = FetchNews('false', 1, 3)\n",
    "false_df = FetchNews('false', 1, 1000, pd.read_csv('datasets/false.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pants on Fire News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pants-fire news page 1...\n",
      "Entry already exists! Stopping execution...\n",
      "Done! Updated dataset with pants-fire news from pages 1 to 1.\n"
     ]
    }
   ],
   "source": [
    "#pants_fire_df = FetchNews('pants-fire', 1, 3)\n",
    "pants_fire_df = FetchNews('pants-fire', 1, 1000, pd.read_csv('datasets/pants-fire.csv', dtype={'label':str}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>quote</th>\n",
       "      <th>context</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>“West Virginia is near last in the U.S.” ranki...</td>\n",
       "      <td>a tweet</td>\n",
       "      <td>Paula Jean Swearengin</td>\n",
       "      <td>September 10, 2020</td>\n",
       "      <td>West Virginia, Environment, Children, Education</td>\n",
       "      <td>Morgan Akers, Rylan Toledo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Illinois has made a \"nation-leading\" inve...</td>\n",
       "      <td>a tweet</td>\n",
       "      <td>JB Pritzker</td>\n",
       "      <td>October 13, 2020</td>\n",
       "      <td>Census, Illinois</td>\n",
       "      <td>Deborah Wilber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\"Mike Parson opposes protections for pre-exist...</td>\n",
       "      <td>a campaign ad</td>\n",
       "      <td>Nicole Galloway</td>\n",
       "      <td>September 26, 2020</td>\n",
       "      <td>Health Care, Missouri</td>\n",
       "      <td>William Skipworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\"I am for protecting pre-existing conditions. ...</td>\n",
       "      <td>a debate</td>\n",
       "      <td>Chris Jacobs</td>\n",
       "      <td>October 21, 2020</td>\n",
       "      <td>Health Care, New York</td>\n",
       "      <td>Jill Terreri Ramos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says U.S. Rep. Ann Wagner “voted five times ag...</td>\n",
       "      <td>a Facebook post</td>\n",
       "      <td>Jill Schupp</td>\n",
       "      <td>September 16, 2020</td>\n",
       "      <td>Health Care, Missouri</td>\n",
       "      <td>Noah Crider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>“Now with the COVID-19 … more people are depen...</td>\n",
       "      <td>an interview with the Washington Examiner</td>\n",
       "      <td>Joe Manchin</td>\n",
       "      <td>August 19, 2020</td>\n",
       "      <td>West Virginia, Drugs, Public Health</td>\n",
       "      <td>Delaney Geiger, Julia Maltby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Now with the COVID-19 … more people are depend...</td>\n",
       "      <td>an interview with the Washington Examiner</td>\n",
       "      <td>Joe Manchin</td>\n",
       "      <td>August 19, 2020</td>\n",
       "      <td>West Virginia, Drugs, Public Health</td>\n",
       "      <td>Delaney Geiger, Julia Maltby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>An “anti-Black Lives Matter” flag replaced the...</td>\n",
       "      <td>Facebook post</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>October 24, 2020</td>\n",
       "      <td>National, Elections, Legal Issues, Wisconsin</td>\n",
       "      <td>Laura Schulte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Upton “voted a dozen times to kick thousands o...</td>\n",
       "      <td>a TV ad</td>\n",
       "      <td>Jon Hoadley</td>\n",
       "      <td>October 13, 2020</td>\n",
       "      <td>Health Care, Michigan</td>\n",
       "      <td>Clara Hendrickson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says she is ranked \"one of the most bipartisan...</td>\n",
       "      <td>comments at a debate</td>\n",
       "      <td>Joni Ernst</td>\n",
       "      <td>October 15, 2020</td>\n",
       "      <td>Bipartisanship, Candidate Biography, Iowa</td>\n",
       "      <td>Rachel Schilke, Rylee Wilson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        label                                              quote  \\\n",
       "0      0  mostly-true  “West Virginia is near last in the U.S.” ranki...   \n",
       "1      1  mostly-true  Says Illinois has made a \"nation-leading\" inve...   \n",
       "2      2  mostly-true  \"Mike Parson opposes protections for pre-exist...   \n",
       "3      3  mostly-true  \"I am for protecting pre-existing conditions. ...   \n",
       "4      4  mostly-true  Says U.S. Rep. Ann Wagner “voted five times ag...   \n",
       "5      5  mostly-true  “Now with the COVID-19 … more people are depen...   \n",
       "6      6  mostly-true  Now with the COVID-19 … more people are depend...   \n",
       "7      7  mostly-true  An “anti-Black Lives Matter” flag replaced the...   \n",
       "8      8  mostly-true  Upton “voted a dozen times to kick thousands o...   \n",
       "9      9  mostly-true  Says she is ranked \"one of the most bipartisan...   \n",
       "\n",
       "                                     context                 author  \\\n",
       "0                                    a tweet  Paula Jean Swearengin   \n",
       "1                                    a tweet            JB Pritzker   \n",
       "2                              a campaign ad        Nicole Galloway   \n",
       "3                                   a debate           Chris Jacobs   \n",
       "4                            a Facebook post            Jill Schupp   \n",
       "5  an interview with the Washington Examiner            Joe Manchin   \n",
       "6  an interview with the Washington Examiner            Joe Manchin   \n",
       "7                              Facebook post         Facebook posts   \n",
       "8                                    a TV ad            Jon Hoadley   \n",
       "9                       comments at a debate             Joni Ernst   \n",
       "\n",
       "                 date                                       categories  \\\n",
       "0  September 10, 2020  West Virginia, Environment, Children, Education   \n",
       "1    October 13, 2020                                 Census, Illinois   \n",
       "2  September 26, 2020                            Health Care, Missouri   \n",
       "3    October 21, 2020                            Health Care, New York   \n",
       "4  September 16, 2020                            Health Care, Missouri   \n",
       "5     August 19, 2020              West Virginia, Drugs, Public Health   \n",
       "6     August 19, 2020              West Virginia, Drugs, Public Health   \n",
       "7    October 24, 2020     National, Elections, Legal Issues, Wisconsin   \n",
       "8    October 13, 2020                            Health Care, Michigan   \n",
       "9    October 15, 2020        Bipartisanship, Candidate Biography, Iowa   \n",
       "\n",
       "                          staff  \n",
       "0    Morgan Akers, Rylan Toledo  \n",
       "1                Deborah Wilber  \n",
       "2             William Skipworth  \n",
       "3            Jill Terreri Ramos  \n",
       "4                   Noah Crider  \n",
       "5  Delaney Geiger, Julia Maltby  \n",
       "6  Delaney Geiger, Julia Maltby  \n",
       "7                 Laura Schulte  \n",
       "8             Clara Hendrickson  \n",
       "9  Rachel Schilke, Rylee Wilson  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostly_true_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDataFrame(df, filename):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# Export dataframes\n",
    "exportDataFrame(true_df, 'datasets/true.csv')\n",
    "exportDataFrame(mostly_true_df, 'datasets/mostly-true.csv')\n",
    "exportDataFrame(half_true_df, 'datasets/half-true.csv')\n",
    "exportDataFrame(barely_true_df, 'datasets/barely-true.csv')\n",
    "exportDataFrame(false_df, 'datasets/false.csv')\n",
    "exportDataFrame(pants_fire_df, 'datasets/pants-fire.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
